{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "runs = mlflow.search_runs(experiment_ids=[\"0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c = Counter(runs['tags.max_accuracy'])\n",
    "c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import conf\n",
    "\n",
    "def gen_plot_dict(runs, x, y, series, dataset, x_label, y_label):\n",
    "    \"\"\"\n",
    "    Will produce a accuracy-by-epsilon graph from an artifact.json\n",
    "    file.\n",
    "    \"\"\"\n",
    "    metrics = runs[[x,y,series,dataset]]\n",
    "    plot_dict = {}\n",
    "    \n",
    "    for index, row in metrics.iterrows():\n",
    "        if row[series] not in plot_dict:\n",
    "            plot_dict[row[series]] = []\n",
    "        if row[x] and row[y]:\n",
    "            plot_dict[row[series]].append((float(row[x]),float(row[y]), row[dataset]))\n",
    "    \n",
    "    return plot_dict\n",
    "\n",
    "def gen_scatter_plot(plot_dict, plot_index, title, label_dict):\n",
    "    colors = ['--r','--b','--g', '--c', '--m', '--y', 'r', 'b', 'g', 'c', 'm', 'y']\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    for i, series in enumerate(plot_dict):\n",
    "        X = {}\n",
    "        Y = {}\n",
    "        points = plot_dict[series]\n",
    "        points.sort(key=lambda x: x[0])\n",
    "        for x, y, d in points:\n",
    "            if d not in X:\n",
    "                X[d] = []\n",
    "            if d not in Y:\n",
    "                Y[d] = []\n",
    "            X[d].append(x)\n",
    "            Y[d].append(y)\n",
    "        for j, d in enumerate(X):\n",
    "            if series:\n",
    "                plt.plot(X[d], Y[d], colors[j+i % len(colors)], label = series + '_' + d)\n",
    "                \n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(label_dict['x_label'])\n",
    "    plt.ylabel(label_dict['y_label'])\n",
    "    plt.figure(plot_index)\n",
    "    plt.show()\n",
    "\n",
    "def make_plots(runs, plots):\n",
    "    for i, p in enumerate(plots):\n",
    "        plot_dict = gen_plot_dict(runs, **plots[p])\n",
    "        gen_scatter_plot(plot_dict, i, p, plots[p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for d in np.unique(runs['tags.dataset'].dropna()):\n",
    "    make_plots(runs, \n",
    "               {\"Synthesizer Comparison ML Classification\": \n",
    "                {'x':'params.epsilon', \n",
    "                 'y':'metrics.max_accuracy', \n",
    "                 'series':'params.synthesizer', \n",
    "                 'dataset':'tags.dataset',\n",
    "                 'x_label': \"epsilon (log scale)\", \n",
    "                 'y_label': \"accuracy (avg. across 10 models)\"},\n",
    "                \"pMSE Comparison\": \n",
    "                {'x':'params.pmse_epsilon', \n",
    "                 'y':'metrics.pmse_score', \n",
    "                 'series':'params.pmse_synthesizer', \n",
    "                 'dataset':'tags.pmse_dataset',\n",
    "                 'x_label': \"epsilon (log scale)\", \n",
    "                 'y_label': \"pmse\"},\n",
    "                \"Wasserstein Comparison\": \n",
    "                {'x':'params.wasserstein_epsilon', \n",
    "                 'y':'metrics.wasserstein_score', \n",
    "                 'series':'params.wasserstein_synthesizer', \n",
    "                 'dataset':'tags.wasserstein_dataset',\n",
    "                 'x_label': \"epsilon (log scale)\", \n",
    "                 'y_label': \"wasserstein\"},\n",
    "                \"AUCROC Comparison\": \n",
    "                {'x':'params.aucroc_epsilon', \n",
    "                 'y':'metrics.aucroc', \n",
    "                 'series':'params.aucroc_synthesizer', \n",
    "                 'dataset':'tags.dataset',\n",
    "                 'x_label': \"epsilon (log scale)\", \n",
    "                 'y_label': \"aucroc\"}\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
